<p align="center">
  <img src="https://github.com/user-attachments/assets/f139cf84-3a20-4694-816e-a75762b8d5bc" alt="adventure">
</p>


# ğŸš€ Python Adventure: From Zero to Hero

Welcome to the Python Adventure: From Zero to Hero! ğŸ† <br> 
This repository is designed for curious minds who want to level up their Python skills <br> 

# ğŸ“Œ Projects in This Adventure

## (1) py-from-zero-to-hero-01 
### ğŸ–¥ï¸ What is it? 
A console-based CRUD application built with Python and SQLite, that contains concepts of: 
- Connecting Python to SQLite ğŸ—„ï¸ 
- Performing Create, Read, Update, Delete (CRUD) operations âœï¸ 
- Running an interactive command-line interface ğŸ—ï¸ 

## (2) py-from-zero-to-hero-02 
### ğŸŒ What is it? 
A Flask-based web API with best practices for: 
- Handling CRUD operations for user management ğŸ› ï¸ 
- Managing configurations with .env and separate dev/prod settings ğŸ”§ 
- Running a Dockerized Flask API for scalable deployment ğŸ³ 
- Using SQLAlchemy for database interactions ğŸ“Š 

## (3) py-from-zero-to-hero-03
### ğŸ¤– What is it?
Building upon everything we accomplished in the previous project, we are now expanding our API with new features as we embark on our journey into the world of LLMs. The enhancements include:

- Utilizing an LLM to determine the topic the user is inquiring about.
- Once the topic is identified, the application attempts to find an answer by scanning the contents of a folder.
- If the topic is not found within the folder's content, the application queries the database to retrieve information related to the user's purchase.
- Lastly, if the user initiates a topic that is not covered by the API, the application returns an appropriate error response.

## (4) py-from-zero-to-hero-04
### ğŸ—¨ï¸ğŸ¤– What is it?
In this final module, we will introduce this fantastic library. 
Instead of manually sending JSON requests to our API, 
we'll leverage a chat assistant to help us to extract the backend information we need more efficiently.

## (5) py-from-zero-to-hero-05
### ğŸ§ ğŸ’¾ What is it?
This project combines RAG (Retrieval-Augmented Generation) with LLMs and local vector databases for intelligent document retrieval. The enhancements include:

- Building a Chroma vector database from documents for semantic search ğŸ”
- Implementing RAG pipelines to retrieve and augment LLM responses with relevant context ğŸ“š
- Integrating Ollama for local LLM inference without external API dependencies ğŸ 
- Managing conversation memory and context across multiple chat interactions ğŸ’¬
- Using Flask to expose chat and query endpoints with intelligent document retrieval ğŸŒ
- Handling embeddings and document chunking with LangChain utilities ğŸ§©

## (6) py-from-zero-to-hero-06
### ğŸ³ğŸš€ What is it?
This is the production-ready version of the RAG/LLM API with enterprise-grade enhancements:

- Dockerized deployment for consistent environments across development and production ğŸ“¦
- Redis integration for caching and session management ğŸ’¾
- Flask-RESTX for structured REST API documentation and swagger support ğŸ“–
- Enhanced profanity filtering and content moderation with better-profanity ğŸ›¡ï¸
- Input validation and sanitization for security ğŸ”
- Modular project structure with separate database, model, and resource layers ğŸ—ï¸
- Production WSGI server (Waitress) instead of Flask's development server ğŸ”§
- Comprehensive Docker orchestration with Redis, Ollama, and Flask containers ğŸ‹

## (7) py-from-zero-to-hero-07
Under construction...
